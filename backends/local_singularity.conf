# This is an example of how you can use the LocalExample backend to define
# a new backend provider. *This is not a complete configuration file!* The
# content here should be copy pasted into the backend -> providers section
# of the cromwell.examples.conf in the root of the repository. You should
# uncomment lines that you want to define, and read carefully to customize
# the file. If you have any questions, please open an issue at
# https://www.github.com/broadinstitute/cromwell/issues

# Documentation
# https://cromwell.readthedocs.io/en/stable/backends/Local/


system {
    abort-jobs-on-terminate=true
}

backend {
  # Override the default backend.
  default = "LocalSingularity"

  # The list of providers.
  providers {
    # Copy paste the contents of a backend provider in this section
    # Examples in cromwell.example.backends include:
    # LocalExample: What you should use if you want to define a new backend provider
    # AWS: Amazon Web Services
    # BCS: Alibaba Cloud Batch Compute
    # TES: protocol defined by GA4GH
    # TESK: the same, with kubernetes support
    # Google Pipelines, v2 (PAPIv2)
    # Docker
    # Singularity: a container safe for HPC
    # Singularity+Slurm: and an example on Slurm
    # udocker: another rootless container solution
    # udocker+slurm: also exemplified on slurm
    # HtCondor: workload manager at UW-Madison
    # LSF: the Platform Load Sharing Facility backend
    # SGE: Sun Grid Engine
    # SLURM: workload manager
    # Spark: cluster

    # Note that these other backend examples will need tweaking and configuration.
    # Please open an issue https://www.github.com/broadinstitute/cromwell if you have any questions

    # The local provider is included by default. This is an example.
    # Define a new backend provider.
    LocalSingularity{
      # The actor that runs the backend. In this case, it's the Shared File System (SFS) ConfigBackend.
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      # The backend custom configuration.
      config {
        filesystems {
            local {
            localization: [
            "hard-link", "soft-link", "cached-copy", "copy"
            ]

                caching {
                # When copying a cached result, what type of file duplication should occur.
                # possible values: "hard-link", "soft-link", "copy", "cached-copy".
                # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem
                # Attempted in the order listed below:
                duplication-strategy: [
                "hard-link", "soft-link", "cached-copy", "copy"
                ]

                # Possible values: md5, xxh64, fingerprint, path, path+modtime
                # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching
                # "md5" will compute an md5 hash of the file content.
                # "xxh64" will compute an xxh64 hash of the file content. Much faster than md5
                # "fingerprint" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.
                # This strategy will only be effective if the duplication-strategy (above) is set to "hard-link", as copying changes the last modified time.
                # "path" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to "soft-link",
                # in order to allow for the original file path to be hashed.
                # "path+modtime" will compute an md5 hash of the file path and the last modified time. The same conditions as for "path" apply here.
                # Default: "md5"
                hashing-strategy: "fingerprint"

                # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint.
                # If the file is smaller than this size the entire file will be read.
                # Default: 10485760 (10MB).
                fingerprint-size: 10485760

                # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.
                # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.
                # Default: false
                check-sibling-md5: false
                }
            }
        }
        # Optional limits on the number of concurrent jobs
        concurrent-job-limit = 64

        # If true submits tools to the bash background using "&". Only usefull for dispatchers that do NOT submit
        # the job and then immediately return a scheduled job id.
        run-in-background = true

        # `temporary-directory` creates the temporary directory for commands.
        #
        # If this value is not set explicitly, the default value creates a unique temporary directory, equivalent to:
        # temporary-directory = "$(mktemp -d \"$PWD\"/tmp.XXXXXX)"
        #
        # The expression is run from the execution directory for the script. The expression must create the directory
        # if it does not exist, and then return the full path to the directory.
        #
        # To create and return a non-random temporary directory, use something like:
        # temporary-directory = "$(mkdir -p /tmp/mydir && echo /tmp/mydir)"

        # `script-epilogue` configures a shell command to run after the execution of every command block.
        #
        # If this value is not set explicitly, the default value is `sync`, equivalent to:
        # script-epilogue = "sync"
        #
        # To turn off the default `sync` behavior set this value to an empty string:
        # script-epilogue = ""

        # `glob-link-command` specifies command used to link glob outputs, by default using hard-links.
        # If filesystem doesn't allow hard-links (e.g., beeGFS), change to soft-links as follows:
        # glob-link-command = "ln -sL GLOB_PATTERN GLOB_DIRECTORY"

        # The list of possible runtime custom attributes.
        runtime-attributes = """
        String? docker
        String? docker_user
        String rt_image = "/nobackup/lab_bsf/users/berguener/singularity/bsf_variant_calling_0.3.sif"
        """

        job-shell="/usr/bin/env bash"
        submit = """
            singularity exec -e --bind /nobackup:/nobackup --bind /research:/research --bind /home:/home \
            ${rt_image} ${job_shell} ${script}
        """

        submit-docker = """
            singularity exec -e --bind /nobackup:/nobackup --bind /research:/research --bind /home:/home \
            --bind ${cwd}:${docker_cwd} ${rt_image} ${job_shell} ${script}
        """

        # Root directory where Cromwell writes job results.  This directory must be
        # visible and writeable by the Cromwell process as well as the jobs that Cromwell
        # launches.
        root = "cromwell-executions"

        # Root directory where Cromwell writes job results in the container. This value
        # can be used to specify where the execution folder is mounted in the container.
        # it is used for the construction of the docker_cwd string in the submit-docker
        # value above.
        dockerRoot = "/cromwell-executions"

        # The defaults for runtime attributes if not provided.
        default-runtime-attributes {
          failOnStderr: false
          continueOnReturnCode: 0
          maxRetries: 3
        }
      }
    }
  }
}

call-caching {
          enabled = true
          invalidate-bad-cache-results = true
      }

database {
          profile = "slick.jdbc.HsqldbProfile$"
          db {
            driver = "org.hsqldb.jdbcDriver"
            # See http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html
            # Shutdown=false. Cromwell will shutdown the database
            # hsqlldb.default_table_type=cached. By default hsqldb uses in memory tables.
            # Setting this to cache for improved memory usage.
            # hsqldb.result_max_memory_rows=10000 . Limits the amount of rows in memory for temp tables
            # hsqldb.tx=mvcc cromwell default. Not changing it. Not clear what this does. http://hsqldb.org/doc/guide/sessions-chapt.html#snc_tx_mvcc
            # hsqldb.large_data=true. Cromwell creates huge DBs that need to be opened.
            # hsqldb.applog=1. Log errors.
            # hsqldb.lob_compressed=true. Compress lobs. This saves a lot of space.
            # hsqldb.script_format=3. Compress script. (uses gzip internally).
            url = """
            jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
            shutdown=false;
            hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
            hsqldb.result_max_memory_rows=100000;
            hsqldb.large_data=true;
            hsqldb.applog=1;
            hsqldb.lob_compressed=true;
            hsqldb.script_format=3
            """
            # Override the cromwell default of only 3 seconds (3000 milliseconds) and allow for 300s to read the database file.
            connectionTimeout = 300000
            numThreads = 1
           }
        }