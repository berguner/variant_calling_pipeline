# This is an example of how you can use the LocalExample backend to define
# a new backend provider. *This is not a complete configuration file!* The
# content here should be copy pasted into the backend -> providers section
# of the cromwell.examples.conf in the root of the repository. You should
# uncomment lines that you want to define, and read carefully to customize
# the file. If you have any questions, please open an issue at
# https://www.github.com/broadinstitute/cromwell/issues

# Documentation
# https://cromwell.readthedocs.io/en/stable/backends/Local/


system {
    abort-jobs-on-terminate=true
}

backend {
  # Override the default backend.
  default = "LocalSingularity"

  # The list of providers.
  providers {
    # Copy paste the contents of a backend provider in this section
    # Examples in cromwell.example.backends include:
    # LocalExample: What you should use if you want to define a new backend provider
    # AWS: Amazon Web Services
    # BCS: Alibaba Cloud Batch Compute
    # TES: protocol defined by GA4GH
    # TESK: the same, with kubernetes support
    # Google Pipelines, v2 (PAPIv2)
    # Docker
    # Singularity: a container safe for HPC
    # Singularity+Slurm: and an example on Slurm
    # udocker: another rootless container solution
    # udocker+slurm: also exemplified on slurm
    # HtCondor: workload manager at UW-Madison
    # LSF: the Platform Load Sharing Facility backend
    # SGE: Sun Grid Engine
    # SLURM: workload manager
    # Spark: cluster

    # Note that these other backend examples will need tweaking and configuration.
    # Please open an issue https://www.github.com/broadinstitute/cromwell if you have any questions

    # The local provider is included by default. This is an example.
    # Define a new backend provider.
    LocalSingularity{
      # The actor that runs the backend. In this case, it's the Shared File System (SFS) ConfigBackend.
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      # The backend custom configuration.
      config {

        # Optional limits on the number of concurrent jobs
        concurrent-job-limit = 32

        # If true submits tools to the bash background using "&". Only usefull for dispatchers that do NOT submit
        # the job and then immediately return a scheduled job id.
        run-in-background = true

        # `temporary-directory` creates the temporary directory for commands.
        #
        # If this value is not set explicitly, the default value creates a unique temporary directory, equivalent to:
        # temporary-directory = "$(mktemp -d \"$PWD\"/tmp.XXXXXX)"
        #
        # The expression is run from the execution directory for the script. The expression must create the directory
        # if it does not exist, and then return the full path to the directory.
        #
        # To create and return a non-random temporary directory, use something like:
        # temporary-directory = "$(mkdir -p /tmp/mydir && echo /tmp/mydir)"

        # `script-epilogue` configures a shell command to run after the execution of every command block.
        #
        # If this value is not set explicitly, the default value is `sync`, equivalent to:
        # script-epilogue = "sync"
        #
        # To turn off the default `sync` behavior set this value to an empty string:
        # script-epilogue = ""

	# `glob-link-command` specifies command used to link glob outputs, by default using hard-links.
	# If filesystem doesn't allow hard-links (e.g., beeGFS), change to soft-links as follows:
	# glob-link-command = "ln -sL GLOB_PATTERN GLOB_DIRECTORY"

	# The list of possible runtime custom attributes.
        runtime-attributes = """
        String? docker
        String? docker_user
        """

        # Submit string when there is no "docker" runtime attribute.
        submit = "/usr/bin/env bash ${script}"

        # Submit string when there is a "docker" runtime attribute.
        submit-docker = """
        singularity exec -e --bind /nobackup:/nobackup --bind /research:/research --bind /home:/home \
            --bind ${cwd}:${docker_cwd} docker://${docker} ${job_shell} ${script}
        """

        # Root directory where Cromwell writes job results.  This directory must be
        # visible and writeable by the Cromwell process as well as the jobs that Cromwell
        # launches.
        root = "cromwell-executions"

        # Root directory where Cromwell writes job results in the container. This value
        # can be used to specify where the execution folder is mounted in the container.
        # it is used for the construction of the docker_cwd string in the submit-docker
        # value above.
        dockerRoot = "/cromwell-executions"

        filesystems {
        local {
           localization: [
             "cached-copy", "hard-link", "soft-link", "copy"
           ]
           hashing-strategy: "fingerprint"
         }
        }

        # The defaults for runtime attributes if not provided.
        default-runtime-attributes {
          failOnStderr: false
          continueOnReturnCode: 0
        }
      }
    }
  }
}

call-caching {
          enabled = true
          invalidate-bad-cache-results = true
      }

database {
          profile = "slick.jdbc.HsqldbProfile$"
          db {
            driver = "org.hsqldb.jdbcDriver"
            # See http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html
            # Shutdown=false. Cromwell will shutdown the database
            # hsqlldb.default_table_type=cached. By default hsqldb uses in memory tables.
            # Setting this to cache for improved memory usage.
            # hsqldb.result_max_memory_rows=10000 . Limits the amount of rows in memory for temp tables
            # hsqldb.tx=mvcc cromwell default. Not changing it. Not clear what this does. http://hsqldb.org/doc/guide/sessions-chapt.html#snc_tx_mvcc
            # hsqldb.large_data=true. Cromwell creates huge DBs that need to be opened.
            # hsqldb.applog=1. Log errors.
            # hsqldb.lob_compressed=true. Compress lobs. This saves a lot of space.
            # hsqldb.script_format=3. Compress script. (uses gzip internally).
            url = """
            jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
            shutdown=false;
            hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
            hsqldb.result_max_memory_rows=100000;
            hsqldb.large_data=true;
            hsqldb.applog=1;
            hsqldb.lob_compressed=true;
            hsqldb.script_format=3
            """
            # Override the cromwell default of only 3 seconds (3000 milliseconds) and allow for 300s to read the database file.
            connectionTimeout = 300000
            numThreads = 1
           }
        }