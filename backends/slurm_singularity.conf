# include the application.conf at the top
system {
  job-rate-control {
    jobs = 10
    per = 1 second
  }
  abort-jobs-on-terminate=true
}

backend {
  default = "Slurm"
  providers {
    Slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
      filesystems {
        local {
           localization: [
             "hard-link", "soft-link", "cached-copy", "copy"
           ]

		   caching {
              # When copying a cached result, what type of file duplication should occur.
              # possible values: "hard-link", "soft-link", "copy", "cached-copy".
              # For more information check: https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem
              # Attempted in the order listed below:
              duplication-strategy: [
                "hard-link", "soft-link", "cached-copy", "copy"
              ]

              # Possible values: md5, xxh64, fingerprint, path, path+modtime
              # For extended explanation check: https://cromwell.readthedocs.io/en/stable/Configuring/#call-caching
              # "md5" will compute an md5 hash of the file content.
              # "xxh64" will compute an xxh64 hash of the file content. Much faster than md5
              # "fingerprint" will take last modified time, size and hash the first 10 mb with xxh64 to create a file fingerprint.
              # This strategy will only be effective if the duplication-strategy (above) is set to "hard-link", as copying changes the last modified time.
              # "path" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to "soft-link",
              # in order to allow for the original file path to be hashed.
              # "path+modtime" will compute an md5 hash of the file path and the last modified time. The same conditions as for "path" apply here.
              # Default: "md5"
              hashing-strategy: "fingerprint"

              # When the 'fingerprint' strategy is used set how much of the beginning of the file is read as fingerprint.
              # If the file is smaller than this size the entire file will be read.
              # Default: 10485760 (10MB).
              fingerprint-size: 10485760

              # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.
              # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.
              # Default: false
              check-sibling-md5: false
            }
         }
        }
        concurrent-job-limit = 100
        runtime-attributes = """
        String rt_time = "12:00:00"
        Int rt_cpus = 2
        Int rt_mem = 8000
        String rt_queue = "covid"
        String rt_additional_parameters = ""
        String rt_image = "/nobackup/lab_bsf/users/berguener/singularity/bsf_variant_calling_0.3.sif"
        String? docker
        String? docker_user
        """

        job-shell="/usr/bin/env bash"
        submit = """
            sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${rt_time} -p ${rt_queue} --qos ${rt_queue} \
            ${rt_additional_parameters} \
            ${"-c " + rt_cpus} --mem=${rt_mem} \
            --wrap "singularity exec -e --bind /nobackup:/nobackup --bind /research:/research --bind /home:/home \
            ${rt_image} ${job_shell} ${script}"
        """

        submit-docker = """sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${rt_time} -p ${rt_queue} --qos ${rt_queue} \
            ${rt_additional_parameters} \
            ${"-c " + rt_cpus} --mem=${rt_mem} \
            --wrap "singularity exec -e --bind /nobackup:/nobackup --bind /research:/research --bind /home:/home \
            --bind ${cwd}:${docker_cwd} ${rt_image} ${job_shell} ${script}"
        """

        kill = "scancel ${job_id}"
        check-alive = "sacct -j ${job_id} -X -n -o state | grep -v \"COMPLETED\\|TIMEOUT\""
        job-id-regex = "Submitted batch job (\\d+)"
        exit-code-timeout-seconds = 1800


        # Root directory where Cromwell writes job results.  This directory must be
        # visible and writeable by the Cromwell process as well as the jobs that Cromwell
        # launches.
        root = "cromwell-executions"

        # Root directory where Cromwell writes job results in the container. This value
        # can be used to specify where the execution folder is mounted in the container.
        # it is used for the construction of the docker_cwd string in the submit-docker
        # value above.
        dockerRoot = "/cromwell-executions"

        # The defaults for runtime attributes if not provided.
        default-runtime-attributes {
          failOnStderr: false
          continueOnReturnCode: 0
          maxRetries: 3
        }
      }
    }
  }
}

call-caching {
          enabled = true
          invalidate-bad-cache-results = true
      }

database {
          profile = "slick.jdbc.HsqldbProfile$"
          db {
            driver = "org.hsqldb.jdbcDriver"
            # See http://hsqldb.org/doc/2.0/guide/dbproperties-chapt.html
            # Shutdown=false. Cromwell will shutdown the database
            # hsqlldb.default_table_type=cached. By default hsqldb uses in memory tables.
            # Setting this to cache for improved memory usage.
            # hsqldb.result_max_memory_rows=10000 . Limits the amount of rows in memory for temp tables
            # hsqldb.tx=mvcc cromwell default. Not changing it. Not clear what this does. http://hsqldb.org/doc/guide/sessions-chapt.html#snc_tx_mvcc
            # hsqldb.large_data=true. Cromwell creates huge DBs that need to be opened.
            # hsqldb.applog=1. Log errors.
            # hsqldb.lob_compressed=true. Compress lobs. This saves a lot of space.
            # hsqldb.script_format=3. Compress script. (uses gzip internally).
            url = """
            jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
            shutdown=false;
            hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
            hsqldb.result_max_memory_rows=1000000;
            hsqldb.large_data=true;
            hsqldb.applog=1;
            hsqldb.lob_compressed=true;
            hsqldb.script_format=3
            """
            # Override the cromwell default of only 3 seconds (3000 milliseconds) and allow for 300s to read the database file.
            connectionTimeout = 300000
            numThreads = 1
           }
        }
